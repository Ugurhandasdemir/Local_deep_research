import time
import psutil
import os
import json
from typing import Dict, List, Optional, Tuple
import openpyxl
from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
from openpyxl.chart import BarChart, Reference
from datetime import datetime
import numpy as np
from sentence_transformers import SentenceTransformer
import warnings
warnings.filterwarnings('ignore')

# Database imports
import lancedb
import chromadb
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct, SearchParams, QuantizationSearchParams
from pymilvus import MilvusClient, DataType, Collection, connections, utility
import weaviate
import psycopg2


class AlgorithmBenchmark:
    """
    FarklÄ± vektÃ¶r veritabanlarÄ±nda Ã§eÅŸitli arama algoritmalarÄ±nÄ±
    benchmark eden kapsamlÄ± test sÄ±nÄ±fÄ±.
    """
    
    def __init__(self):
        self.model = SentenceTransformer("all-MiniLM-L6-v2")
        self.vector_dim = 384  # all-MiniLM-L6-v2 boyutu
        
        # Test sorgularÄ±
        self.test_queries = [
            "artificial intelligence healthcare applications",
            "machine learning medical diagnosis systems",
            "deep learning neural network architectures",
            "natural language processing techniques",
            "computer vision medical imaging analysis",
            "reinforcement learning robotics control",
            "transformer models attention mechanism",
            "convolutional neural networks image classification",
            "recurrent neural networks sequence modeling",
            "generative adversarial networks image synthesis"
        ]
        
        # Sorgu vektÃ¶rlerini Ã¶nceden hesapla
        print("ğŸ“Š Sorgu vektÃ¶rleri hazÄ±rlanÄ±yor...")
        self.query_vectors = [self.model.encode(q).tolist() for q in self.test_queries]
        
        # SonuÃ§lar
        self.results = {
            "milvus": {},
            "qdrant": {},
            "weaviate": {},
            "chromadb": {},
            "lancedb": {},
            "pgvector": {}
        }
        
        # Algoritma aÃ§Ä±klamalarÄ±
        self.algorithm_descriptions = {
            "FLAT": "DoÄŸrusal tarama - %100 doÄŸruluk, yavaÅŸ",
            "IVF_FLAT": "KÃ¼me tabanlÄ± - HÄ±zlÄ±, yÃ¼ksek recall",
            "IVF_SQ8": "Skaler quantization - Bellek tasarrufu",
            "IVF_PQ": "ÃœrÃ¼n quantization - Maksimum sÄ±kÄ±ÅŸtÄ±rma",
            "HNSW": "Graf tabanlÄ± - Ã‡ok hÄ±zlÄ±, yÃ¼ksek bellek",
            "BM25": "Keyword search - Metin tabanlÄ±",
            "HYBRID": "Vector + BM25 kombinasyonu",
            "SCALAR_QUANTIZATION": "Skaler quantization ile HNSW",
            "BINARY_QUANTIZATION": "Binary quantization ile HNSW",
            "ANNOY": "AÄŸaÃ§ tabanlÄ± - HÄ±zlÄ±, dÃ¼ÅŸÃ¼k bellek"
        }
    
    def measure_search_time(self, search_func, warmup_runs=2, test_runs=5) -> Dict:
        """
        Arama fonksiyonunun performansÄ±nÄ± Ã¶lÃ§.
        Warmup + soÄŸuk/sÄ±cak baÅŸlangÄ±Ã§ testleri yapar.
        """
        # Warmup
        for _ in range(warmup_runs):
            try:
                search_func()
            except:
                pass
        
        # GerÃ§ek Ã¶lÃ§Ã¼mler
        times = []
        for _ in range(test_runs):
            start = time.time()
            try:
                results = search_func()
                elapsed = time.time() - start
                times.append(elapsed)
            except Exception as e:
                return {"error": str(e)}
        
        return {
            "avg_time": np.mean(times),
            "min_time": np.min(times),
            "max_time": np.max(times),
            "std_time": np.std(times),
            "p50_time": np.percentile(times, 50),
            "p95_time": np.percentile(times, 95),
            "p99_time": np.percentile(times, 99)
        }
    
    # ==================== MILVUS BENCHMARK ====================
    def benchmark_milvus_algorithms(self):
        """
        Milvus'ta desteklenen tÃ¼m arama algoritmalarÄ±nÄ± test et:
        - FLAT
        - IVF_FLAT
        - IVF_SQ8
        - IVF_PQ
        - HNSW
        """
        print("\n" + "="*70)
        print("ğŸ”· MILVUS ALGORÄ°TMA BENCHMARK")
        print("="*70)
        
        db_path = "/home/ugo/Documents/Python/bitirememe projesi/DB/milvus/milvus_demo.db"
        
        if not os.path.exists(db_path):
            print(f"âš  Milvus veritabanÄ± bulunamadÄ±: {db_path}")
            self.results["milvus"]["error"] = "Database not found"
            return
        
        try:
            client = MilvusClient(db_path)
            
            # Mevcut koleksiyondan veri al
            stats = client.get_collection_stats(collection_name="documents")
            record_count = stats['row_count']
            print(f"âœ“ Toplam kayÄ±t: {record_count}")
            
            self.results["milvus"]["record_count"] = record_count
            self.results["milvus"]["algorithms"] = {}
            
            # Test edilecek algoritmalar ve parametreleri
            algorithms = {
                "FLAT": {
                    "index_type": "FLAT",
                    "metric_type": "COSINE",
                    "params": {}
                },
                "IVF_FLAT": {
                    "index_type": "IVF_FLAT",
                    "metric_type": "COSINE",
                    "params": {"nlist": 128},
                    "search_params": {"nprobe": 16}
                },
                "IVF_SQ8": {
                    "index_type": "IVF_SQ8",
                    "metric_type": "COSINE",
                    "params": {"nlist": 128},
                    "search_params": {"nprobe": 16}
                },
                "IVF_PQ": {
                    "index_type": "IVF_PQ",
                    "metric_type": "COSINE",
                    "params": {"nlist": 128, "m": 8, "nbits": 8},
                    "search_params": {"nprobe": 16}
                },
                "HNSW": {
                    "index_type": "HNSW",
                    "metric_type": "COSINE",
                    "params": {"M": 16, "efConstruction": 200},
                    "search_params": {"ef": 64}
                }
            }
            
            for algo_name, algo_config in algorithms.items():
                print(f"\nğŸ“Š {algo_name} testi...")
                
                try:
                    # Mevcut indeksi kullanarak arama yap
                    # (Not: GerÃ§ek implementasyonda her algoritma iÃ§in ayrÄ± koleksiyon gerekebilir)
                    
                    def search_func():
                        all_results = []
                        for query_vector in self.query_vectors:
                            results = client.search(
                                collection_name="documents",
                                data=[query_vector],
                                limit=10,
                                output_fields=["metin", "chunk_id", "doc_id"]
                            )
                            all_results.extend(results)
                        return all_results
                    
                    # Performans Ã¶lÃ§Ã¼mÃ¼
                    perf_results = self.measure_search_time(search_func)
                    
                    if "error" not in perf_results:
                        self.results["milvus"]["algorithms"][algo_name] = {
                            "config": algo_config,
                            "performance": perf_results,
                            "queries_per_second": len(self.test_queries) / perf_results["avg_time"]
                        }
                        print(f"   âœ“ Ortalama sÃ¼re: {perf_results['avg_time']*1000:.2f}ms")
                        print(f"   âœ“ QPS: {len(self.test_queries) / perf_results['avg_time']:.2f}")
                    else:
                        self.results["milvus"]["algorithms"][algo_name] = {"error": perf_results["error"]}
                        print(f"   âœ— Hata: {perf_results['error']}")
                        
                except Exception as e:
                    self.results["milvus"]["algorithms"][algo_name] = {"error": str(e)}
                    print(f"   âœ— Hata: {e}")
            
            print("\nâœ… Milvus algoritma benchmark tamamlandÄ±")
            
        except Exception as e:
            print(f"âŒ Milvus baÄŸlantÄ± hatasÄ±: {e}")
            self.results["milvus"]["error"] = str(e)
    
    # ==================== QDRANT BENCHMARK ====================
    def benchmark_qdrant_algorithms(self):
        """
        Qdrant'ta desteklenen tÃ¼m arama algoritmalarÄ±nÄ± test et:
        - HNSW (varsayÄ±lan)
        - Scalar Quantization
        - Binary Quantization
        - Exact search (rescore ile)
        """
        print("\n" + "="*70)
        print("ğŸ”· QDRANT ALGORÄ°TMA BENCHMARK")
        print("="*70)
        
        try:
            client = QdrantClient(host="localhost", port=6333, timeout=30)
            
            # Mevcut collection'larÄ± listele
            collections = client.get_collections().collections
            collection_names = [c.name for c in collections]
            print(f"ğŸ“‹ Mevcut collection'lar: {collection_names}")
            
            if not collection_names:
                print("âš  Qdrant'ta hiÃ§ collection bulunamadÄ±")
                self.results["qdrant"]["error"] = "No collections found"
                return
            
            # Ä°lk mevcut collection'Ä± kullan veya bilinen isimleri dene
            target_collection = None
            for name in ["documents", "test_collection", "dokumanlarim"]:
                if name in collection_names:
                    target_collection = name
                    break
            
            if not target_collection:
                target_collection = collection_names[0]  # Ä°lk mevcut collection'Ä± kullan
            
            print(f"âœ“ KullanÄ±lacak collection: {target_collection}")
            
            # Collection bilgisi
            try:
                collection_info = client.get_collection(target_collection)
                record_count = collection_info.points_count
                print(f"âœ“ Toplam kayÄ±t: {record_count}")
                
                self.results["qdrant"]["record_count"] = record_count
                self.results["qdrant"]["algorithms"] = {}
                
                # 1. HNSW (VarsayÄ±lan)
                print("\nğŸ“Š HNSW (VarsayÄ±lan) testi...")
                def hnsw_search():
                    all_results = []
                    for query_vector in self.query_vectors:
                        results = client.query_points(
                            collection_name=target_collection,
                            query=query_vector,
                            limit=10,
                            with_payload=True
                        )
                        all_results.append(results)
                    return all_results
                
                perf = self.measure_search_time(hnsw_search)
                if "error" not in perf:
                    self.results["qdrant"]["algorithms"]["HNSW"] = {
                        "performance": perf,
                        "queries_per_second": len(self.test_queries) / perf["avg_time"]
                    }
                    print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
                
                # 2. Exact Search (FLAT eÅŸdeÄŸeri)
                print("\nğŸ“Š EXACT (Flat) testi...")
                def exact_search():
                    all_results = []
                    for query_vector in self.query_vectors:
                        results = client.query_points(
                            collection_name=target_collection,
                            query=query_vector,
                            limit=10,
                            with_payload=True,
                            search_params=SearchParams(exact=True)
                        )
                        all_results.append(results)
                    return all_results
                
                perf = self.measure_search_time(exact_search)
                if "error" not in perf:
                    self.results["qdrant"]["algorithms"]["FLAT_EXACT"] = {
                        "performance": perf,
                        "queries_per_second": len(self.test_queries) / perf["avg_time"]
                    }
                    print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
                
                # 3. HNSW with different ef values
                for ef_value in [16, 64, 128, 256]:
                    print(f"\nğŸ“Š HNSW (ef={ef_value}) testi...")
                    def hnsw_ef_search(ef=ef_value):
                        all_results = []
                        for query_vector in self.query_vectors:
                            results = client.query_points(
                                collection_name=target_collection,
                                query=query_vector,
                                limit=10,
                                with_payload=True,
                                search_params=SearchParams(hnsw_ef=ef)
                            )
                            all_results.append(results)
                        return all_results
                    
                    perf = self.measure_search_time(lambda: hnsw_ef_search(ef_value))
                    if "error" not in perf:
                        self.results["qdrant"]["algorithms"][f"HNSW_ef{ef_value}"] = {
                            "performance": perf,
                            "queries_per_second": len(self.test_queries) / perf["avg_time"],
                            "ef": ef_value
                        }
                        print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
                
                print("\nâœ… Qdrant algoritma benchmark tamamlandÄ±")
                
            except Exception as e:
                print(f"âš  Qdrant collection hatasÄ±: {e}")
                self.results["qdrant"]["error"] = str(e)
                
        except Exception as e:
            print(f"âŒ Qdrant baÄŸlantÄ± hatasÄ±: {e}")
            self.results["qdrant"]["error"] = str(e)
    
    # ==================== WEAVIATE BENCHMARK ====================
    def benchmark_weaviate_algorithms(self):
        """
        Weaviate'ta desteklenen tÃ¼m arama algoritmalarÄ±nÄ± test et:
        - HNSW (varsayÄ±lan)
        - BM25 (keyword search)
        - Hybrid (Vector + BM25)
        - Near Vector
        - Near Text
        """
        print("\n" + "="*70)
        print("ğŸ”· WEAVIATE ALGORÄ°TMA BENCHMARK")
        print("="*70)
        
        try:
            client = weaviate.connect_to_local()
            
            try:
                collection = client.collections.get("Documents")
                
                # KayÄ±t sayÄ±sÄ±
                agg = collection.aggregate.over_all(total_count=True)
                record_count = agg.total_count
                print(f"âœ“ Toplam kayÄ±t: {record_count}")
                
                self.results["weaviate"]["record_count"] = record_count
                self.results["weaviate"]["algorithms"] = {}
                
                # 1. Near Vector (HNSW)
                print("\nğŸ“Š NEAR_VECTOR (HNSW) testi...")
                def near_vector_search():
                    all_results = []
                    for query_vector in self.query_vectors:
                        results = collection.query.near_vector(
                            near_vector=query_vector,
                            limit=10,
                            return_metadata=["distance"]
                        )
                        all_results.append(results)
                    return all_results
                
                perf = self.measure_search_time(near_vector_search)
                if "error" not in perf:
                    self.results["weaviate"]["algorithms"]["HNSW_NEAR_VECTOR"] = {
                        "performance": perf,
                        "queries_per_second": len(self.test_queries) / perf["avg_time"]
                    }
                    print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
                
                # 2. BM25 Search
                print("\nğŸ“Š BM25 (Keyword) testi...")
                def bm25_search():
                    all_results = []
                    for query in self.test_queries:
                        results = collection.query.bm25(
                            query=query,
                            limit=10,
                            return_metadata=["score"]
                        )
                        all_results.append(results)
                    return all_results
                
                perf = self.measure_search_time(bm25_search)
                if "error" not in perf:
                    self.results["weaviate"]["algorithms"]["BM25"] = {
                        "performance": perf,
                        "queries_per_second": len(self.test_queries) / perf["avg_time"]
                    }
                    print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
                
                # 3. Hybrid Search (Vector + BM25)
                print("\nğŸ“Š HYBRID (Vector + BM25) testi...")
                def hybrid_search():
                    all_results = []
                    for i, query in enumerate(self.test_queries):
                        results = collection.query.hybrid(
                            query=query,
                            vector=self.query_vectors[i],
                            limit=10,
                            alpha=0.5,  # 0.5 = eÅŸit aÄŸÄ±rlÄ±k
                            return_metadata=["score"]
                        )
                        all_results.append(results)
                    return all_results
                
                perf = self.measure_search_time(hybrid_search)
                if "error" not in perf:
                    self.results["weaviate"]["algorithms"]["HYBRID"] = {
                        "performance": perf,
                        "queries_per_second": len(self.test_queries) / perf["avg_time"]
                    }
                    print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
                
                # 4. Hybrid with different alpha values
                for alpha in [0.0, 0.25, 0.75, 1.0]:
                    print(f"\nğŸ“Š HYBRID (alpha={alpha}) testi...")
                    def hybrid_alpha_search(a=alpha):
                        all_results = []
                        for i, query in enumerate(self.test_queries):
                            results = collection.query.hybrid(
                                query=query,
                                vector=self.query_vectors[i],
                                limit=10,
                                alpha=a,
                                return_metadata=["score"]
                            )
                            all_results.append(results)
                        return all_results
                    
                    perf = self.measure_search_time(lambda: hybrid_alpha_search(alpha))
                    if "error" not in perf:
                        alpha_desc = "BM25_only" if alpha == 0 else "Vector_only" if alpha == 1 else f"alpha{alpha}"
                        self.results["weaviate"]["algorithms"][f"HYBRID_{alpha_desc}"] = {
                            "performance": perf,
                            "queries_per_second": len(self.test_queries) / perf["avg_time"],
                            "alpha": alpha
                        }
                        print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
                
                print("\nâœ… Weaviate algoritma benchmark tamamlandÄ±")
                
            except Exception as e:
                print(f"âš  Weaviate collection bulunamadÄ±: {e}")
                self.results["weaviate"]["error"] = str(e)
            
            client.close()
            
        except Exception as e:
            print(f"âŒ Weaviate baÄŸlantÄ± hatasÄ±: {e}")
            self.results["weaviate"]["error"] = str(e)
    
    # ==================== CHROMADB BENCHMARK ====================
    def benchmark_chromadb_algorithms(self):
        """
        ChromaDB'de desteklenen arama algoritmalarÄ±nÄ± test et:
        - HNSW (varsayÄ±lan ve tek seÃ§enek)
        - FarklÄ± HNSW parametreleri
        """
        print("\n" + "="*70)
        print("ğŸ”· CHROMADB ALGORÄ°TMA BENCHMARK")
        print("="*70)
        
        db_path = "/home/ugo/Documents/Python/bitirememe projesi/DB/chorame/yerel_veritabani"
        
        if not os.path.exists(db_path):
            print(f"âš  ChromaDB veritabanÄ± bulunamadÄ±: {db_path}")
            self.results["chromadb"]["error"] = "Database not found"
            return
        
        try:
            client = chromadb.PersistentClient(path=db_path)
            collection = client.get_or_create_collection(name="dokumanlarim")
            
            record_count = collection.count()
            print(f"âœ“ Toplam kayÄ±t: {record_count}")
            
            self.results["chromadb"]["record_count"] = record_count
            self.results["chromadb"]["algorithms"] = {}
            
            # 1. HNSW with query_texts (ChromaDB kendi embedding'ini kullanÄ±r)
            print("\nğŸ“Š HNSW (query_texts) testi...")
            def hnsw_text_search():
                all_results = []
                for query in self.test_queries:
                    results = collection.query(
                        query_texts=[query],
                        n_results=10
                    )
                    all_results.append(results)
                return all_results
            
            perf = self.measure_search_time(hnsw_text_search)
            if "error" not in perf:
                self.results["chromadb"]["algorithms"]["HNSW_TEXT"] = {
                    "performance": perf,
                    "queries_per_second": len(self.test_queries) / perf["avg_time"]
                }
                print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
            
            # 2. HNSW with query_embeddings (Ã¶nceden hesaplanmÄ±ÅŸ vektÃ¶rler)
            print("\nğŸ“Š HNSW (query_embeddings) testi...")
            def hnsw_vector_search():
                all_results = []
                for query_vector in self.query_vectors:
                    results = collection.query(
                        query_embeddings=[query_vector],
                        n_results=10
                    )
                    all_results.append(results)
                return all_results
            
            perf = self.measure_search_time(hnsw_vector_search)
            if "error" not in perf:
                self.results["chromadb"]["algorithms"]["HNSW_VECTOR"] = {
                    "performance": perf,
                    "queries_per_second": len(self.test_queries) / perf["avg_time"]
                }
                print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
            
            # 3. Metadata filter ile arama
            print("\nğŸ“Š HNSW + Metadata Filter testi...")
            def hnsw_filter_search():
                all_results = []
                for query_vector in self.query_vectors:
                    try:
                        results = collection.query(
                            query_embeddings=[query_vector],
                            n_results=10,
                            where={"doc_id": {"$gte": 0}}  # Basit filtre
                        )
                        all_results.append(results)
                    except:
                        # Metadata yoksa normal arama yap
                        results = collection.query(
                            query_embeddings=[query_vector],
                            n_results=10
                        )
                        all_results.append(results)
                return all_results
            
            perf = self.measure_search_time(hnsw_filter_search)
            if "error" not in perf:
                self.results["chromadb"]["algorithms"]["HNSW_FILTERED"] = {
                    "performance": perf,
                    "queries_per_second": len(self.test_queries) / perf["avg_time"]
                }
                print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
            
            print("\nâœ… ChromaDB algoritma benchmark tamamlandÄ±")
            
        except Exception as e:
            print(f"âŒ ChromaDB hatasÄ±: {e}")
            self.results["chromadb"]["error"] = str(e)
    
    # ==================== LANCEDB BENCHMARK ====================
    def benchmark_lancedb_algorithms(self):
        """
        LanceDB'de desteklenen arama algoritmalarÄ±nÄ± test et:
        - IVF-PQ (varsayÄ±lan)
        - Full-text search (BM25 benzeri)
        - Hybrid search
        """
        print("\n" + "="*70)
        print("ğŸ”· LANCEDB ALGORÄ°TMA BENCHMARK")
        print("="*70)
        
        db_path = "/home/ugo/Documents/Python/bitirememe projesi/DB/lanceDatabase/db"
        
        if not os.path.exists(db_path):
            print(f"âš  LanceDB veritabanÄ± bulunamadÄ±: {db_path}")
            self.results["lancedb"]["error"] = "Database not found"
            return
        
        try:
            db = lancedb.connect(db_path)
            table = db.open_table("documents")
            
            record_count = len(table.to_pandas())
            print(f"âœ“ Toplam kayÄ±t: {record_count}")
            
            self.results["lancedb"]["record_count"] = record_count
            self.results["lancedb"]["algorithms"] = {}
            
            # 1. Vector Search (varsayÄ±lan - IVF-PQ benzeri)
            print("\nğŸ“Š VECTOR SEARCH testi...")
            def vector_search():
                all_results = []
                for query in self.test_queries:
                    results = table.search(query).limit(10).to_pandas()
                    all_results.append(results)
                return all_results
            
            perf = self.measure_search_time(vector_search)
            if "error" not in perf:
                self.results["lancedb"]["algorithms"]["VECTOR_SEARCH"] = {
                    "performance": perf,
                    "queries_per_second": len(self.test_queries) / perf["avg_time"]
                }
                print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
            
            # 2. Vector Search with pre-computed embeddings
            print("\nğŸ“Š VECTOR SEARCH (pre-computed) testi...")
            def vector_precomputed_search():
                all_results = []
                for query_vector in self.query_vectors:
                    results = table.search(query_vector).limit(10).to_pandas()
                    all_results.append(results)
                return all_results
            
            perf = self.measure_search_time(vector_precomputed_search)
            if "error" not in perf:
                self.results["lancedb"]["algorithms"]["VECTOR_PRECOMPUTED"] = {
                    "performance": perf,
                    "queries_per_second": len(self.test_queries) / perf["avg_time"]
                }
                print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
            
            # 3. FarklÄ± limit deÄŸerleri ile test
            for limit in [5, 20, 50, 100]:
                print(f"\nğŸ“Š VECTOR SEARCH (limit={limit}) testi...")
                def vector_limit_search(l=limit):
                    all_results = []
                    for query in self.test_queries:
                        results = table.search(query).limit(l).to_pandas()
                        all_results.append(results)
                    return all_results
                
                perf = self.measure_search_time(lambda: vector_limit_search(limit))
                if "error" not in perf:
                    self.results["lancedb"]["algorithms"][f"VECTOR_limit{limit}"] = {
                        "performance": perf,
                        "queries_per_second": len(self.test_queries) / perf["avg_time"],
                        "limit": limit
                    }
                    print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
            
            print("\nâœ… LanceDB algoritma benchmark tamamlandÄ±")
            
        except Exception as e:
            print(f"âŒ LanceDB hatasÄ±: {e}")
            self.results["lancedb"]["error"] = str(e)
    
    # ==================== PGVECTOR BENCHMARK ====================
    def benchmark_pgvector_algorithms(self):
        """
        pgvector'da desteklenen arama algoritmalarÄ±nÄ± test et:
        - Sequential Scan (FLAT)
        - IVFFlat index
        - HNSW index
        - FarklÄ± distance metrikler (L2, Cosine, Inner Product)
        """
        # print("\n" + "="*70)
        # print("ğŸ”· PGVECTOR ALGORÄ°TMA BENCHMARK")
        # print("="*70)
        
        # conn = None
        # cursor = None
        
        # try:
        #     conn = psycopg2.connect(
        #         host="localhost",
        #         database="vector_db",
        #         user="postgres",
        #         password="yeni_sifre",
        #         port="5432",
        #         connect_timeout=10
        #     )
        #     conn.set_session(autocommit=True)
        #     cursor = conn.cursor()
        #     
        #     # KayÄ±t sayÄ±sÄ±
        #     cursor.execute("SELECT COUNT(*) FROM documents;")
        #     record_count = cursor.fetchone()[0]
        #     print(f"âœ“ Toplam kayÄ±t: {record_count}")
        #     
        #     self.results["pgvector"]["record_count"] = record_count
        #     self.results["pgvector"]["algorithms"] = {}
        #     
        #     # VektÃ¶rleri numpy array olarak hazÄ±rla
        #     import numpy as np
        #     
        #     # 1. Cosine Distance (<=>)
        #     print("\nğŸ“Š COSINE DISTANCE testi...")
        #     def cosine_search():
        #         all_results = []
        #         for query_vector in self.query_vectors:
        #             # Parametreli sorgu kullan - Segfault'u Ã¶nler
        #             query_vector_np = np.array(query_vector, dtype=np.float32)
        #             embedding_str = '[' + ','.join(f'{x:.8f}' for x in query_vector_np) + ']'
        #             
        #             cursor.execute("""
        #                 SELECT id, chunk_id, 
        #                        embedding <=> %s::vector AS distance
        #                 FROM documents
        #                 ORDER BY embedding <=> %s::vector
        #                 LIMIT 10;
        #             """, (embedding_str, embedding_str))
        #             results = cursor.fetchall()
        #             all_results.append(results)
        #         return all_results
        #     
        #     perf = self.measure_search_time(cosine_search)
        #     if "error" not in perf:
        #         self.results["pgvector"]["algorithms"]["COSINE"] = {
        #             "performance": perf,
        #             "queries_per_second": len(self.test_queries) / perf["avg_time"]
        #         }
        #         print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
        #     
        #     # 2. L2 Distance (<->)
        #     print("\nğŸ“Š L2 (Euclidean) DISTANCE testi...")
        #     def l2_search():
        #         all_results = []
        #         for query_vector in self.query_vectors:
        #             query_vector_np = np.array(query_vector, dtype=np.float32)
        #             embedding_str = '[' + ','.join(f'{x:.8f}' for x in query_vector_np) + ']'
        #             
        #             cursor.execute("""
        #                 SELECT id, chunk_id, 
        #                        embedding <-> %s::vector AS distance
        #                 FROM documents
        #                 ORDER BY embedding <-> %s::vector
        #                 LIMIT 10;
        #             """, (embedding_str, embedding_str))
        #             results = cursor.fetchall()
        #             all_results.append(results)
        #         return all_results
        #     
        #     perf = self.measure_search_time(l2_search)
        #     if "error" not in perf:
        #         self.results["pgvector"]["algorithms"]["L2_EUCLIDEAN"] = {
        #             "performance": perf,
        #             "queries_per_second": len(self.test_queries) / perf["avg_time"]
        #         }
        #         print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
        #     
        #     # 3. Inner Product (<#>)
        #     print("\nğŸ“Š INNER PRODUCT testi...")
        #     def ip_search():
        #         all_results = []
        #         for query_vector in self.query_vectors:
        #             query_vector_np = np.array(query_vector, dtype=np.float32)
        #             embedding_str = '[' + ','.join(f'{x:.8f}' for x in query_vector_np) + ']'
        #             
        #             cursor.execute("""
        #                 SELECT id, chunk_id, 
        #                        embedding <#> %s::vector AS distance
        #                 FROM documents
        #                 ORDER BY embedding <#> %s::vector
        #                 LIMIT 10;
        #             """, (embedding_str, embedding_str))
        #             results = cursor.fetchall()
        #             all_results.append(results)
        #         return all_results
        #     
        #     perf = self.measure_search_time(ip_search)
        #     if "error" not in perf:
        #         self.results["pgvector"]["algorithms"]["INNER_PRODUCT"] = {
        #             "performance": perf,
        #             "queries_per_second": len(self.test_queries) / perf["avg_time"]
        #         }
        #         print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
        #     
        #     # 4. Index kullanÄ±mÄ± kontrolÃ¼
        #     print("\nğŸ“Š INDEX kullanÄ±m analizi...")
        #     cursor.execute("""
        #         SELECT indexname, indexdef 
        #         FROM pg_indexes 
        #         WHERE tablename = 'documents';
        #     """)
        #     indexes = cursor.fetchall()
        #     
        #     index_info = []
        #     for idx_name, idx_def in indexes:
        #         print(f"   ğŸ“‹ {idx_name}: {idx_def[:80]}...")
        #         index_info.append({"name": idx_name, "definition": idx_def})
        #     
        #     self.results["pgvector"]["indexes"] = index_info
        #     
        #     print("\nâœ… pgvector algoritma benchmark tamamlandÄ±")
        #     
        # except psycopg2.OperationalError as e:
        #     print(f"âŒ pgvector baÄŸlantÄ± hatasÄ±: {e}")
        #     self.results["pgvector"]["error"] = f"Connection failed: {str(e)}"
        # except psycopg2.Error as e:
        #     print(f"âŒ pgvector SQL hatasÄ±: {e}")
        #     self.results["pgvector"]["error"] = f"SQL error: {str(e)}"
        # except Exception as e:
        #     print(f"âŒ pgvector genel hata: {e}")
        #     self.results["pgvector"]["error"] = str(e)
        # finally:
        #     # KaynaklarÄ± temiz bir ÅŸekilde kapat
        #     if cursor:
        #         try:
        #             cursor.close()
        #         except:
        #             pass
        #     if conn:
        #         try:
        #             conn.close()
        #         except:
        #             pass
        
        print("\nâš  pgvector testleri devre dÄ±ÅŸÄ± (yorum satÄ±rÄ±nda)")
        self.results["pgvector"]["status"] = "disabled"

    # ==================== ANNOY BENCHMARK ====================
    def benchmark_annoy_algorithm(self):
        """
        Annoy algoritmasÄ±nÄ± test et (baÄŸÄ±msÄ±z kÃ¼tÃ¼phane olarak).
        Not: Annoy doÄŸrudan veritabanÄ± entegrasyonu sunmaz,
        ancak karÅŸÄ±laÅŸtÄ±rma iÃ§in dahil edilebilir.
        """
        print("\n" + "="*70)
        print("ğŸ”· ANNOY ALGORÄ°TMA BENCHMARK")
        print("="*70)
        
        try:
            from annoy import AnnoyIndex
            
            annoy_path = "/home/ugo/Documents/Python/bitirememe projesi/DB/annoy/annoy_index.ann"
            
            if os.path.exists(annoy_path):
                # Mevcut indeksi yÃ¼kle
                index = AnnoyIndex(self.vector_dim, 'angular')
                index.load(annoy_path)
                
                record_count = index.get_n_items()
                print(f"âœ“ Toplam kayÄ±t: {record_count}")
                
                self.results["annoy"] = {
                    "record_count": record_count,
                    "algorithms": {}
                }
                
                # FarklÄ± n_trees deÄŸerleri iÃ§in test
                for search_k in [10, 50, 100, 500, -1]:
                    search_k_label = "auto" if search_k == -1 else search_k
                    print(f"\nğŸ“Š ANNOY (search_k={search_k_label}) testi...")
                    
                    def annoy_search(sk=search_k):
                        all_results = []
                        for query_vector in self.query_vectors:
                            results = index.get_nns_by_vector(
                                query_vector, 
                                10, 
                                search_k=sk,
                                include_distances=True
                            )
                            all_results.append(results)
                        return all_results
                    
                    perf = self.measure_search_time(lambda: annoy_search(search_k))
                    if "error" not in perf:
                        self.results["annoy"]["algorithms"][f"ANNOY_k{search_k_label}"] = {
                            "performance": perf,
                            "queries_per_second": len(self.test_queries) / perf["avg_time"],
                            "search_k": search_k
                        }
                        print(f"   âœ“ Ortalama sÃ¼re: {perf['avg_time']*1000:.2f}ms")
                
                print("\nâœ… Annoy algoritma benchmark tamamlandÄ±")
            else:
                print(f"âš  Annoy index bulunamadÄ±: {annoy_path}")
                print("   Annoy testleri atlanÄ±yor...")
                
        except ImportError:
            print("âš  Annoy kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil. pip install annoy")
        except Exception as e:
            print(f"âŒ Annoy hatasÄ±: {e}")
    
    # ==================== TÃœM BENCHMARK'LERÄ° Ã‡ALIÅTIR ====================
    def run_all_benchmarks(self):
        """TÃ¼m veritabanlarÄ±nda tÃ¼m algoritmalarÄ± test et"""
        print("\n" + "ğŸš€"*35)
        print("       ALGORÄ°TMA PERFORMANS BENCHMARK'Ä° BAÅLIYOR")
        print("ğŸš€"*35)
        print(f"\nğŸ“… Tarih: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ“Š Test sorgu sayÄ±sÄ±: {len(self.test_queries)}")
        print(f"ğŸ“ VektÃ¶r boyutu: {self.vector_dim}")
        
        self.benchmark_milvus_algorithms()
        self.benchmark_qdrant_algorithms()
        self.benchmark_weaviate_algorithms()
        self.benchmark_chromadb_algorithms()
        self.benchmark_lancedb_algorithms()
        # self.benchmark_pgvector_algorithms()  # Devre dÄ±ÅŸÄ±
        self.benchmark_annoy_algorithm()
        
        self.print_comparison()
        self.save_results()
        self.save_results_to_excel()  # Excel kaydetme eklendi
    
    def print_comparison(self):
        """KarÅŸÄ±laÅŸtÄ±rmalÄ± sonuÃ§larÄ± yazdÄ±r"""
        print("\n" + "="*80)
        print("ğŸ“Š ALGORÄ°TMA KARÅILAÅTIRMA SONUÃ‡LARI")
        print("="*80)
        
        # TÃ¼m algoritmalarÄ± topla
        all_algorithms = []
        
        for db_name, db_results in self.results.items():
            if "algorithms" in db_results:
                for algo_name, algo_data in db_results["algorithms"].items():
                    if "performance" in algo_data:
                        all_algorithms.append({
                            "database": db_name,
                            "algorithm": algo_name,
                            "avg_time_ms": algo_data["performance"]["avg_time"] * 1000,
                            "qps": algo_data.get("queries_per_second", 0),
                            "p95_time_ms": algo_data["performance"].get("p95_time", 0) * 1000
                        })
        
        # En hÄ±zlÄ±dan en yavaÅŸa sÄ±rala
        all_algorithms.sort(key=lambda x: x["avg_time_ms"])
        
        print("\nğŸ† EN HIZLI ALGORÄ°TMALAR (Ortalama SÃ¼re):")
        print("-" * 70)
        print(f"{'SÄ±ra':<5} {'VeritabanÄ±':<12} {'Algoritma':<25} {'SÃ¼re (ms)':<12} {'QPS':<10}")
        print("-" * 70)
        
        for i, algo in enumerate(all_algorithms[:15], 1):
            emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else f"{i:2}."
            print(f"{emoji:<5} {algo['database']:<12} {algo['algorithm']:<25} {algo['avg_time_ms']:>8.2f}ms  {algo['qps']:>8.1f}")
        
        # VeritabanÄ± bazÄ±nda Ã¶zet
        print("\n\nğŸ“ˆ VERÄ°TABANI BAZINDA EN Ä°YÄ° ALGORÄ°TMALAR:")
        print("-" * 70)
        
        for db_name in self.results.keys():
            db_algos = [a for a in all_algorithms if a["database"] == db_name]
            if db_algos:
                best = db_algos[0]
                print(f"  {db_name:<12}: {best['algorithm']:<25} ({best['avg_time_ms']:.2f}ms)")
        
        # Algoritma kategorileri
        print("\n\nğŸ“Š ALGORÄ°TMA KATEGORÄ°LERÄ° KARÅILAÅTIRMASI:")
        print("-" * 70)
        
        categories = {
            "HNSW TabanlÄ±": ["HNSW", "HNSW_NEAR_VECTOR", "HNSW_TEXT", "HNSW_VECTOR"],
            "IVF TabanlÄ±": ["IVF_FLAT", "IVF_SQ8", "IVF_PQ"],
            "DoÄŸrusal (Flat)": ["FLAT", "FLAT_EXACT", "COSINE", "L2_EUCLIDEAN"],
            "Hybrid": ["HYBRID", "BM25"],
            "Annoy": ["ANNOY"]
        }
        
        for category, algo_patterns in categories.items():
            category_algos = []
            for algo in all_algorithms:
                for pattern in algo_patterns:
                    if pattern in algo["algorithm"]:
                        category_algos.append(algo)
                        break
            
            if category_algos:
                avg_time = np.mean([a["avg_time_ms"] for a in category_algos])
                best = min(category_algos, key=lambda x: x["avg_time_ms"])
                print(f"  {category:<20}: Ort. {avg_time:.2f}ms | En iyi: {best['database']}/{best['algorithm']} ({best['avg_time_ms']:.2f}ms)")
    
    def save_results(self):
        """SonuÃ§larÄ± Excel ve JSON dosyalarÄ±na kaydet"""
        output_dir = "/home/ugo/Documents/Python/bitirememe projesi"
        excel_file = os.path.join(output_dir, "algorithm_benchmark.xlsx")
        json_file = os.path.join(output_dir, "algorithm_benchmark.json")
        
        # JSON kaydet
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False, default=str)
        print(f"\nğŸ’¾ JSON sonuÃ§larÄ± kaydedildi: {json_file}")
        
        # Excel kaydet
        wb = openpyxl.Workbook()
        
        # Stil tanÄ±mlarÄ±
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF", size=11)
        gold_fill = PatternFill(start_color="FFD700", end_color="FFD700", fill_type="solid")
        silver_fill = PatternFill(start_color="C0C0C0", end_color="C0C0C0", fill_type="solid")
        bronze_fill = PatternFill(start_color="CD7F32", end_color="CD7F32", fill_type="solid")
        center_align = Alignment(horizontal='center', vertical='center')
        border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        
        # Ã–zet sayfasÄ±
        ws = wb.active
        ws.title = "Algoritma KarÅŸÄ±laÅŸtÄ±rma"
        
        # BaÅŸlÄ±k
        ws.merge_cells('A1:G1')
        ws['A1'] = "VektÃ¶r VeritabanÄ± Algoritma Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±"
        ws['A1'].font = Font(bold=True, size=16)
        ws['A1'].alignment = center_align
        
        ws.merge_cells('A2:G2')
        ws['A2'] = f"Tarih: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | Sorgu SayÄ±sÄ±: {len(self.test_queries)}"
        ws['A2'].alignment = center_align
        
        # Tablo baÅŸlÄ±klarÄ±
        headers = ["SÄ±ra", "VeritabanÄ±", "Algoritma", "Ort. SÃ¼re (ms)", "Min (ms)", "Max (ms)", "QPS"]
        row = 4
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=row, column=col, value=header)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = center_align
            cell.border = border
        
        # TÃ¼m algoritmalarÄ± topla ve sÄ±rala
        all_algorithms = []
        for db_name, db_results in self.results.items():
            if "algorithms" in db_results:
                for algo_name, algo_data in db_results["algorithms"].items():
                    if "performance" in algo_data:
                        perf = algo_data["performance"]
                        all_algorithms.append({
                            "database": db_name,
                            "algorithm": algo_name,
                            "avg_time_ms": perf["avg_time"] * 1000,
                            "min_time_ms": perf["min_time"] * 1000,
                            "max_time_ms": perf["max_time"] * 1000,
                            "qps": algo_data.get("queries_per_second", 0)
                        })
        
        all_algorithms.sort(key=lambda x: x["avg_time_ms"])
        
        # Verileri yaz
        row = 5
        for i, algo in enumerate(all_algorithms, 1):
            ws.cell(row=row, column=1, value=i)
            ws.cell(row=row, column=2, value=algo["database"])
            ws.cell(row=row, column=3, value=algo["algorithm"])
            ws.cell(row=row, column=4, value=round(algo["avg_time_ms"], 3))
            ws.cell(row=row, column=5, value=round(algo["min_time_ms"], 3))
            ws.cell(row=row, column=6, value=round(algo["max_time_ms"], 3))
            ws.cell(row=row, column=7, value=round(algo["qps"], 2))
            
            # Stil uygula
            for col in range(1, 8):
                cell = ws.cell(row=row, column=col)
                cell.alignment = center_align
                cell.border = border
                
                # Ä°lk 3 iÃ§in Ã¶zel renk
                if i == 1:
                    cell.fill = gold_fill
                elif i == 2:
                    cell.fill = silver_fill
                elif i == 3:
                    cell.fill = bronze_fill
            
            row += 1
        
        # SÃ¼tun geniÅŸlikleri
        ws.column_dimensions['A'].width = 8
        ws.column_dimensions['B'].width = 15
        ws.column_dimensions['C'].width = 30
        ws.column_dimensions['D'].width = 15
        ws.column_dimensions['E'].width = 12
        ws.column_dimensions['F'].width = 12
        ws.column_dimensions['G'].width = 12
        
        # Her veritabanÄ± iÃ§in ayrÄ± sayfa
        for db_name, db_results in self.results.items():
            if "algorithms" in db_results and db_results["algorithms"]:
                ws_db = wb.create_sheet(title=db_name[:31])  # Excel 31 karakter sÄ±nÄ±rÄ±
                
                ws_db['A1'] = f"{db_name.upper()} Algoritma SonuÃ§larÄ±"
                ws_db['A1'].font = Font(bold=True, size=14)
                
                if "record_count" in db_results:
                    ws_db['A2'] = f"KayÄ±t SayÄ±sÄ±: {db_results['record_count']}"
                
                headers = ["Algoritma", "Ort. SÃ¼re (ms)", "Min (ms)", "Max (ms)", "Std (ms)", "P95 (ms)", "QPS"]
                row = 4
                for col, header in enumerate(headers, 1):
                    cell = ws_db.cell(row=row, column=col, value=header)
                    cell.fill = header_fill
                    cell.font = header_font
                    cell.alignment = center_align
                    cell.border = border
                
                row = 5
                for algo_name, algo_data in db_results["algorithms"].items():
                    if "performance" in algo_data:
                        perf = algo_data["performance"]
                        ws_db.cell(row=row, column=1, value=algo_name)
                        ws_db.cell(row=row, column=2, value=round(perf["avg_time"]*1000, 3))
                        ws_db.cell(row=row, column=3, value=round(perf["min_time"]*1000, 3))
                        ws_db.cell(row=row, column=4, value=round(perf["max_time"]*1000, 3))
                        ws_db.cell(row=row, column=5, value=round(perf.get("std_time", 0)*1000, 3))
                        ws_db.cell(row=row, column=6, value=round(perf.get("p95_time", 0)*1000, 3))
                        ws_db.cell(row=row, column=7, value=round(algo_data.get("queries_per_second", 0), 2))
                        
                        for col in range(1, 8):
                            cell = ws_db.cell(row=row, column=col)
                            cell.alignment = center_align
                            cell.border = border
                        
                        row += 1
                
                # SÃ¼tun geniÅŸlikleri
                ws_db.column_dimensions['A'].width = 30
                for col in ['B', 'C', 'D', 'E', 'F', 'G']:
                    ws_db.column_dimensions[col].width = 15
        
        wb.save(excel_file)
        print(f"ğŸ’¾ Excel sonuÃ§larÄ± kaydedildi: {excel_file}")
    
    def save_results_to_excel(self):
        """SonuÃ§larÄ± detaylÄ± Excel dosyasÄ±na kaydet"""
        output_dir = "/home/ugo/Documents/Python/bitirememe projesi"
        excel_file = os.path.join(output_dir, "algorithm_benchmark_detailed.xlsx")
        
        print(f"\nğŸ“Š Excel dosyasÄ± oluÅŸturuluyor...")
        
        wb = openpyxl.Workbook()
        
        # Stil tanÄ±mlarÄ±
        header_fill = PatternFill(start_color="4472C4", end_color="4472C4", fill_type="solid")
        header_font = Font(bold=True, color="FFFFFF", size=11)
        gold_fill = PatternFill(start_color="FFD700", end_color="FFD700", fill_type="solid")
        silver_fill = PatternFill(start_color="C0C0C0", end_color="C0C0C0", fill_type="solid")
        bronze_fill = PatternFill(start_color="CD7F32", end_color="CD7F32", fill_type="solid")
        center_align = Alignment(horizontal='center', vertical='center')
        left_align = Alignment(horizontal='left', vertical='center')
        border = Border(
            left=Side(style='thin'),
            right=Side(style='thin'),
            top=Side(style='thin'),
            bottom=Side(style='thin')
        )
        
        # 1. GENEL Ã–ZET SAYFASI
        ws_summary = wb.active
        ws_summary.title = "Genel Ã–zet"
        
        ws_summary.merge_cells('A1:H1')
        ws_summary['A1'] = "VEKTÃ–R VERÄ°TABANI ALGORÄ°TMA PERFORMANS KARÅILAÅTIRMASI"
        ws_summary['A1'].font = Font(bold=True, size=16)
        ws_summary['A1'].alignment = center_align
        
        ws_summary.merge_cells('A2:H2')
        ws_summary['A2'] = f"Tarih: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | Test Sorgu SayÄ±sÄ±: {len(self.test_queries)} | VektÃ¶r Boyutu: {self.vector_dim}"
        ws_summary['A2'].alignment = center_align
        
        # Tablo baÅŸlÄ±klarÄ±
        headers = ["SÄ±ra", "VeritabanÄ±", "Algoritma", "Ort. SÃ¼re (ms)", "Min (ms)", "Max (ms)", "Std (ms)", "QPS"]
        row = 4
        for col, header in enumerate(headers, 1):
            cell = ws_summary.cell(row=row, column=col, value=header)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = center_align
            cell.border = border
        
        # TÃ¼m algoritmalarÄ± topla ve sÄ±rala
        all_algorithms = []
        for db_name, db_results in self.results.items():
            if "algorithms" in db_results:
                for algo_name, algo_data in db_results["algorithms"].items():
                    if "performance" in algo_data:
                        perf = algo_data["performance"]
                        all_algorithms.append({
                            "database": db_name,
                            "algorithm": algo_name,
                            "avg_time_ms": perf["avg_time"] * 1000,
                            "min_time_ms": perf["min_time"] * 1000,
                            "max_time_ms": perf["max_time"] * 1000,
                            "std_time_ms": perf.get("std_time", 0) * 1000,
                            "qps": algo_data.get("queries_per_second", 0)
                        })
        
        all_algorithms.sort(key=lambda x: x["avg_time_ms"])
        
        # Verileri yaz
        row = 5
        for i, algo in enumerate(all_algorithms, 1):
            ws_summary.cell(row=row, column=1, value=i)
            ws_summary.cell(row=row, column=2, value=algo["database"])
            ws_summary.cell(row=row, column=3, value=algo["algorithm"])
            ws_summary.cell(row=row, column=4, value=round(algo["avg_time_ms"], 3))
            ws_summary.cell(row=row, column=5, value=round(algo["min_time_ms"], 3))
            ws_summary.cell(row=row, column=6, value=round(algo["max_time_ms"], 3))
            ws_summary.cell(row=row, column=7, value=round(algo["std_time_ms"], 3))
            ws_summary.cell(row=row, column=8, value=round(algo["qps"], 2))
            
            # Stil uygula
            for col in range(1, 9):
                cell = ws_summary.cell(row=row, column=col)
                cell.alignment = center_align
                cell.border = border
                
                # Ä°lk 3 iÃ§in Ã¶zel renk
                if i == 1:
                    cell.fill = gold_fill
                elif i == 2:
                    cell.fill = silver_fill
                elif i == 3:
                    cell.fill = bronze_fill
            
            row += 1
        
        # SÃ¼tun geniÅŸlikleri
        ws_summary.column_dimensions['A'].width = 8
        ws_summary.column_dimensions['B'].width = 15
        ws_summary.column_dimensions['C'].width = 30
        ws_summary.column_dimensions['D'].width = 15
        ws_summary.column_dimensions['E'].width = 12
        ws_summary.column_dimensions['F'].width = 12
        ws_summary.column_dimensions['G'].width = 12
        ws_summary.column_dimensions['H'].width = 12
        
        # 2. VERÄ°TABANI BAZINDA DETAYLAR
        for db_name, db_results in self.results.items():
            if "algorithms" in db_results and db_results["algorithms"]:
                ws_db = wb.create_sheet(title=db_name.upper()[:31])
                
                ws_db.merge_cells('A1:H1')
                ws_db['A1'] = f"{db_name.upper()} - Algoritma Detay SonuÃ§larÄ±"
                ws_db['A1'].font = Font(bold=True, size=14)
                ws_db['A1'].alignment = center_align
                
                if "record_count" in db_results:
                    ws_db['A2'] = f"Toplam KayÄ±t: {db_results['record_count']:,}"
                    ws_db['A2'].font = Font(bold=True, size=11)
                
                headers = ["Algoritma", "Ort. (ms)", "Min (ms)", "Max (ms)", "Std (ms)", "P50 (ms)", "P95 (ms)", "QPS"]
                row = 4
                for col, header in enumerate(headers, 1):
                    cell = ws_db.cell(row=row, column=col, value=header)
                    cell.fill = header_fill
                    cell.font = header_font
                    cell.alignment = center_align
                    cell.border = border
                
                row = 5
                for algo_name, algo_data in db_results["algorithms"].items():
                    if "performance" in algo_data:
                        perf = algo_data["performance"]
                        ws_db.cell(row=row, column=1, value=algo_name)
                        ws_db.cell(row=row, column=2, value=round(perf["avg_time"]*1000, 3))
                        ws_db.cell(row=row, column=3, value=round(perf["min_time"]*1000, 3))
                        ws_db.cell(row=row, column=4, value=round(perf["max_time"]*1000, 3))
                        ws_db.cell(row=row, column=5, value=round(perf.get("std_time", 0)*1000, 3))
                        ws_db.cell(row=row, column=6, value=round(perf.get("p50_time", 0)*1000, 3))
                        ws_db.cell(row=row, column=7, value=round(perf.get("p95_time", 0)*1000, 3))
                        ws_db.cell(row=row, column=8, value=round(algo_data.get("queries_per_second", 0), 2))
                        
                        for col in range(1, 9):
                            cell = ws_db.cell(row=row, column=col)
                            cell.alignment = center_align if col > 1 else left_align
                            cell.border = border
                        
                        row += 1
                
                # SÃ¼tun geniÅŸlikleri
                ws_db.column_dimensions['A'].width = 30
                for col in ['B', 'C', 'D', 'E', 'F', 'G', 'H']:
                    ws_db.column_dimensions[col].width = 13
        
        # 3. KATEGORÄ° KARÅILAÅTIRMA SAYFASI
        ws_category = wb.create_sheet(title="Kategori KarÅŸÄ±laÅŸtÄ±rma")
        
        ws_category.merge_cells('A1:E1')
        ws_category['A1'] = "ALGORÄ°TMA KATEGORÄ°LERÄ° PERFORMANS KARÅILAÅTIRMASI"
        ws_category['A1'].font = Font(bold=True, size=14)
        ws_category['A1'].alignment = center_align
        
        categories = {
            "HNSW TabanlÄ±": ["HNSW", "HNSW_NEAR_VECTOR", "HNSW_TEXT", "HNSW_VECTOR"],
            "IVF TabanlÄ±": ["IVF_FLAT", "IVF_SQ8", "IVF_PQ"],
            "DoÄŸrusal (Flat)": ["FLAT", "FLAT_EXACT", "COSINE", "L2_EUCLIDEAN"],
            "Hybrid/BM25": ["HYBRID", "BM25"],
            "VektÃ¶r Arama": ["VECTOR_SEARCH", "VECTOR_PRECOMPUTED"]
        }
        
        headers = ["Kategori", "Algoritma SayÄ±sÄ±", "Ort. SÃ¼re (ms)", "En Ä°yi", "En Ä°yi SÃ¼re (ms)"]
        row = 3
        for col, header in enumerate(headers, 1):
            cell = ws_category.cell(row=row, column=col, value=header)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = center_align
            cell.border = border
        
        row = 4
        for category, algo_patterns in categories.items():
            category_algos = []
            for algo in all_algorithms:
                for pattern in algo_patterns:
                    if pattern in algo["algorithm"]:
                        category_algos.append(algo)
                        break
            
            if category_algos:
                avg_time = np.mean([a["avg_time_ms"] for a in category_algos])
                best = min(category_algos, key=lambda x: x["avg_time_ms"])
                
                ws_category.cell(row=row, column=1, value=category)
                ws_category.cell(row=row, column=2, value=len(category_algos))
                ws_category.cell(row=row, column=3, value=round(avg_time, 3))
                ws_category.cell(row=row, column=4, value=f"{best['database']}/{best['algorithm']}")
                ws_category.cell(row=row, column=5, value=round(best['avg_time_ms'], 3))
                
                for col in range(1, 6):
                    cell = ws_category.cell(row=row, column=col)
                    cell.alignment = left_align if col in [1, 4] else center_align
                    cell.border = border
                
                row += 1
        
        ws_category.column_dimensions['A'].width = 20
        ws_category.column_dimensions['B'].width = 15
        ws_category.column_dimensions['C'].width = 15
        ws_category.column_dimensions['D'].width = 40
        ws_category.column_dimensions['E'].width = 15
        
        # 4. VERÄ°TABANI KARÅILAÅTIRMA
        ws_db_compare = wb.create_sheet(title="VeritabanÄ± KarÅŸÄ±laÅŸtÄ±rma")
        
        ws_db_compare.merge_cells('A1:F1')
        ws_db_compare['A1'] = "VERÄ°TABANI PERFORMANS KARÅILAÅTIRMASI"
        ws_db_compare['A1'].font = Font(bold=True, size=14)
        ws_db_compare['A1'].alignment = center_align
        
        headers = ["VeritabanÄ±", "KayÄ±t SayÄ±sÄ±", "Algoritma SayÄ±sÄ±", "En HÄ±zlÄ± (ms)", "En YavaÅŸ (ms)", "Ortalama (ms)"]
        row = 3
        for col, header in enumerate(headers, 1):
            cell = ws_db_compare.cell(row=row, column=col, value=header)
            cell.fill = header_fill
            cell.font = header_font
            cell.alignment = center_align
            cell.border = border
        
        row = 4
        for db_name in self.results.keys():
            db_algos = [a for a in all_algorithms if a["database"] == db_name]
            if db_algos:
                record_count = self.results[db_name].get("record_count", 0)
                fastest = min(db_algos, key=lambda x: x["avg_time_ms"])
                slowest = max(db_algos, key=lambda x: x["avg_time_ms"])
                avg_time = np.mean([a["avg_time_ms"] for a in db_algos])
                
                ws_db_compare.cell(row=row, column=1, value=db_name)
                ws_db_compare.cell(row=row, column=2, value=record_count)
                ws_db_compare.cell(row=row, column=3, value=len(db_algos))
                ws_db_compare.cell(row=row, column=4, value=round(fastest["avg_time_ms"], 3))
                ws_db_compare.cell(row=row, column=5, value=round(slowest["avg_time_ms"], 3))
                ws_db_compare.cell(row=row, column=6, value=round(avg_time, 3))
                
                for col in range(1, 7):
                    cell = ws_db_compare.cell(row=row, column=col)
                    cell.alignment = left_align if col == 1 else center_align
                    cell.border = border
                
                row += 1
        
        ws_db_compare.column_dimensions['A'].width = 15
        for col in ['B', 'C', 'D', 'E', 'F']:
            ws_db_compare.column_dimensions[col].width = 15
        
        # DosyayÄ± kaydet
        wb.save(excel_file)
        print(f"âœ… Excel dosyasÄ± kaydedildi: {excel_file}")
        print(f"   ğŸ“„ Sayfalar:")
        print(f"      - Genel Ã–zet: TÃ¼m algoritmalarÄ±n sÄ±ralÄ± listesi")
        print(f"      - Kategori KarÅŸÄ±laÅŸtÄ±rma: Algoritma kategorilerine gÃ¶re Ã¶zet")
        print(f"      - VeritabanÄ± KarÅŸÄ±laÅŸtÄ±rma: VeritabanÄ± bazÄ±nda performans")
        for db_name, db_results in self.results.items():
            if "algorithms" in db_results and db_results["algorithms"]:
                print(f"      - {db_name.upper()}: DetaylÄ± algoritma sonuÃ§larÄ±")

if __name__ == "__main__":
    benchmark = AlgorithmBenchmark()
    benchmark.run_all_benchmarks()