import psycopg2
from sentence_transformers import SentenceTransformer
import time

# PostgreSQL baÄŸlantÄ±sÄ±
def connect_db():
    try:
        conn = psycopg2.connect(
            host="localhost",
            database="vector_db",
            user="postgres",
            password="yeni_sifre",
            port="5432",
            connect_timeout=10
        )
        conn.set_session(autocommit=True)
        return conn
    except Exception as e:
        print(f"âœ— BaÄŸlantÄ± hatasÄ±: {e}")
        return None

# Embedding modeli
model = SentenceTransformer("all-MiniLM-L6-v2")

# KayÄ±t sayÄ±sÄ±nÄ± kontrol et
def check_record_count(conn):
    cursor = conn.cursor()
    try:
        cursor.execute("SELECT COUNT(*) FROM documents;")
        count = cursor.fetchone()[0]
        return count
    except Exception as e:
        print(f"âœ— KayÄ±t sayÄ±sÄ± kontrol hatasÄ±: {e}")
        return 0
    finally:
        cursor.close()

# Cosine Distance ile arama (<=>)
def search_cosine(conn, query_text, limit=5):
    """Cosine distance kullanarak vektÃ¶r aramasÄ± yapar"""
    cursor = conn.cursor()
    query_vector = model.encode(query_text).tolist()
    embedding_str = '[' + ','.join(f'{x:.8f}' for x in query_vector) + ']'
    
    try:
        cursor.execute("""
            SELECT id, chunk_id, doc_id, filename, metin, 
                   1 - (embedding <=> %s::vector) AS similarity
            FROM documents
            ORDER BY embedding <=> %s::vector
            LIMIT %s;
        """, (embedding_str, embedding_str, limit))
        results = cursor.fetchall()
        return results
    except Exception as e:
        print(f"âœ— Cosine arama hatasÄ±: {e}")
        return []
    finally:
        cursor.close()

# L2 (Euclidean) Distance ile arama (<->)
def search_l2(conn, query_text, limit=5):
    """L2 (Euclidean) distance kullanarak vektÃ¶r aramasÄ± yapar"""
    cursor = conn.cursor()
    query_vector = model.encode(query_text).tolist()
    embedding_str = '[' + ','.join(f'{x:.8f}' for x in query_vector) + ']'
    
    try:
        cursor.execute("""
            SELECT id, chunk_id, doc_id, filename, metin, 
                   embedding <-> %s::vector AS distance
            FROM documents
            ORDER BY embedding <-> %s::vector
            LIMIT %s;
        """, (embedding_str, embedding_str, limit))
        results = cursor.fetchall()
        return results
    except Exception as e:
        print(f"âœ— L2 arama hatasÄ±: {e}")
        return []
    finally:
        cursor.close()

# Inner Product ile arama (<#>)
def search_inner_product(conn, query_text, limit=5):
    """Inner product kullanarak vektÃ¶r aramasÄ± yapar"""
    cursor = conn.cursor()
    query_vector = model.encode(query_text).tolist()
    embedding_str = '[' + ','.join(f'{x:.8f}' for x in query_vector) + ']'
    
    try:
        cursor.execute("""
            SELECT id, chunk_id, doc_id, filename, metin, 
                   (embedding <#> %s::vector) * -1 AS similarity
            FROM documents
            ORDER BY embedding <#> %s::vector
            LIMIT %s;
        """, (embedding_str, embedding_str, limit))
        results = cursor.fetchall()
        return results
    except Exception as e:
        print(f"âœ— Inner product arama hatasÄ±: {e}")
        return []
    finally:
        cursor.close()

# FiltrelenmiÅŸ arama (doc_id ile)
def search_with_filter(conn, query_text, doc_id=None, limit=5):
    """Doc ID filtresi ile cosine similarity aramasÄ± yapar"""
    cursor = conn.cursor()
    query_vector = model.encode(query_text).tolist()
    embedding_str = '[' + ','.join(f'{x:.8f}' for x in query_vector) + ']'
    
    try:
        if doc_id is not None:
            cursor.execute("""
                SELECT id, chunk_id, doc_id, filename, metin, 
                       1 - (embedding <=> %s::vector) AS similarity
                FROM documents
                WHERE doc_id = %s
                ORDER BY embedding <=> %s::vector
                LIMIT %s;
            """, (embedding_str, doc_id, embedding_str, limit))
        else:
            cursor.execute("""
                SELECT id, chunk_id, doc_id, filename, metin, 
                       1 - (embedding <=> %s::vector) AS similarity
                FROM documents
                ORDER BY embedding <=> %s::vector
                LIMIT %s;
            """, (embedding_str, embedding_str, limit))
        
        results = cursor.fetchall()
        return results
    except Exception as e:
        print(f"âœ— FiltrelenmiÅŸ arama hatasÄ±: {e}")
        return []
    finally:
        cursor.close()

# Ä°lk N kaydÄ± gÃ¶ster
def show_first_documents(conn, limit=5):
    cursor = conn.cursor()
    try:
        cursor.execute("""
            SELECT id, chunk_id, doc_id, filename, metin
            FROM documents
            ORDER BY id
            LIMIT %s;
        """, (limit,))
        results = cursor.fetchall()
        return results
    except Exception as e:
        print(f"âœ— Veri gÃ¶sterme hatasÄ±: {e}")
        return []
    finally:
        cursor.close()

# Index bilgilerini gÃ¶ster
def show_indexes(conn):
    cursor = conn.cursor()
    try:
        cursor.execute("""
            SELECT indexname, indexdef 
            FROM pg_indexes 
            WHERE tablename = 'documents';
        """)
        indexes = cursor.fetchall()
        return indexes
    except Exception as e:
        print(f"âœ— Index bilgisi hatasÄ±: {e}")
        return []
    finally:
        cursor.close()

# Ana fonksiyon
def main():
    conn = connect_db()
    if not conn:
        return
    
    try:
        print("âœ“ PostgreSQL + pgvector'e baÄŸlanÄ±ldÄ±\n")
        
        # KayÄ±t sayÄ±sÄ±nÄ± kontrol et
        count = check_record_count(conn)
        print(f"âœ“ VeritabanÄ±nda {count} adet kayÄ±t bulunmaktadÄ±r\n")
        
        if count == 0:
            print("âš  VeritabanÄ±nda veri yok! Ã–nce write_vector_database.py Ã§alÄ±ÅŸtÄ±rÄ±n.")
            return
        
        # Index bilgilerini gÃ¶ster
        print("="*60)
        print("INDEX BÄ°LGÄ°LERÄ°")
        print("="*60)
        indexes = show_indexes(conn)
        for idx_name, idx_def in indexes:
            print(f"ðŸ“‹ {idx_name}")
            print(f"   {idx_def[:100]}...")
        print()
        
        # Test sorgularÄ±
        queries = [
            "artificial intelligence healthcare",
            "machine learning medical diagnosis",
            "deep learning neural networks"
        ]
        
        for query in queries:
            print("="*60)
            print(f"SORGU: '{query}'")
            print("="*60)
            
            # Cosine Similarity Search
            print("\nðŸ“Š COSINE SIMILARITY SEARCH:")
            print("-"*60)
            start = time.time()
            results = search_cosine(conn, query, limit=3)
            search_time = time.time() - start
            print(f"Arama zamanÄ±: {search_time:.4f}s\n")
            
            for idx, (id, chunk_id, doc_id, filename, metin, similarity) in enumerate(results, 1):
                print(f"{idx}. SonuÃ§ (Benzerlik: {similarity:.4f})")
                print(f"   ID: {id} | Doc ID: {doc_id} | Chunk: {chunk_id}")
                print(f"   Filename: {filename}")
                print(f"   Metin: {metin[:150]}...\n")
            
            # L2 Distance Search
            print("ðŸ“Š L2 (EUCLIDEAN) DISTANCE SEARCH:")
            print("-"*60)
            start = time.time()
            results = search_l2(conn, query, limit=3)
            search_time = time.time() - start
            print(f"Arama zamanÄ±: {search_time:.4f}s\n")
            
            for idx, (id, chunk_id, doc_id, filename, metin, distance) in enumerate(results, 1):
                print(f"{idx}. SonuÃ§ (Distance: {distance:.4f})")
                print(f"   ID: {id} | Doc ID: {doc_id} | Chunk: {chunk_id}")
                print(f"   Filename: {filename}")
                print(f"   Metin: {metin[:150]}...\n")
            
            # Inner Product Search
            print("ðŸ“Š INNER PRODUCT SEARCH:")
            print("-"*60)
            start = time.time()
            results = search_inner_product(conn, query, limit=3)
            search_time = time.time() - start
            print(f"Arama zamanÄ±: {search_time:.4f}s\n")
            
            for idx, (id, chunk_id, doc_id, filename, metin, similarity) in enumerate(results, 1):
                print(f"{idx}. SonuÃ§ (Similarity: {similarity:.4f})")
                print(f"   ID: {id} | Doc ID: {doc_id} | Chunk: {chunk_id}")
                print(f"   Filename: {filename}")
                print(f"   Metin: {metin[:150]}...\n")
            
            print("\n")
        
        # Belirli bir dÃ¶kÃ¼man iÃ§inde arama
        print("="*60)
        print("BELÄ°RLÄ° DÃ–KÃœMANDA ARAMA (Doc ID: 0)")
        print("="*60)
        query = "artificial intelligence"
        start = time.time()
        results = search_with_filter(conn, query, doc_id=0, limit=3)
        search_time = time.time() - start
        print(f"Sorgu: '{query}'")
        print(f"Arama zamanÄ±: {search_time:.4f}s\n")
        
        for idx, (id, chunk_id, doc_id, filename, metin, similarity) in enumerate(results, 1):
            print(f"{idx}. SonuÃ§ (Benzerlik: {similarity:.4f})")
            print(f"   ID: {id} | Doc ID: {doc_id} | Chunk: {chunk_id}")
            print(f"   Filename: {filename}")
            print(f"   Metin: {metin[:150]}...\n")
        
        # Ä°lk 5 kaydÄ± gÃ¶ster
        print("="*60)
        print("Ä°LK 5 KAYIT")
        print("="*60)
        first_records = show_first_documents(conn, limit=5)
        for idx, (id, chunk_id, doc_id, filename, metin) in enumerate(first_records, 1):
            print(f"\n{idx}. ID: {id} | Doc ID: {doc_id} | Chunk: {chunk_id}")
            print(f"   Filename: {filename}")
            print(f"   Metin: {metin[:200]}...")
            
    finally:
        conn.close()
        print("\nâœ“ PostgreSQL baÄŸlantÄ±sÄ± kapatÄ±ldÄ±")

if __name__ == "__main__":
    main()